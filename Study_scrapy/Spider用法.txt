Spider要做的事就是如下两件：
#定义爬取的网站的动作；
#分析爬取下来的网页；

Spider类基础属性：
#name。爬虫名称，是定义Spider名字的字符串。Spider的名字定义了Scrapy如何定位并初始化Spider，它必须是唯一的。不过我们可以生成多个相同的Spider实例，数量没有限制。name是Spider最重要的属性。如果Spider爬取单个网站，一个常见的做法是以该网站的域名名称来命令Spider。
#allowed_domains。允许爬取的域名，是可选配置，不在此范围的连接不会被跟进爬去。
#start_urls。起始URL列表，当我们没有实现start_requests()方法时，默认会从这个列表开始抓取。
#custom_settings。它是一个字典，是专属于本Spider的配置，此设置会覆盖项目全局的设置。此设置必须在初始化前被更新，必须定义成类变量。
#crawler。它是由from_crawler()方法设置的，代表的是本Spider类对应大的Crawler对象。Crawler对象包含了很多项目组件，利用它我们可以获取项目的一些配置信息，如最常见的获取项目的设置信息，即Settings。
#settings。它是一个Settings对象，利用它我们可以直接获取项目的全局设置变量。

Spider常用方法:
#start_requests()。此方法用于生成初始请求，它必须返回一个可迭代对象。此方法会默认使用start_urls里面的URL来构造Request，而且Request是GET请求方法。如果我们想在启动时以POST方式访问某个站点，可以直接重写这个方法，发送POST请求时使用FormRequest即可
#parse()。当Response没有指定回调函数时，该方法会默认被调用。它负责处理Response，处理返回结果，并从中提取出想要的数据和下一步的请求，然后返回。该方法需要返回一个包含Response或Item的可迭代对象。
#closed()。当Spider关闭时，该方法会被调用，在这里一般会定义释放资源的一些操作或其他收尾操作。
